"""
RAG ì±—ë´‡ì„ ìœ„í•œ ë©”ì¸ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ì…ë‹ˆë‹¤.

ì´ íŒŒì¼ì€ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(UI), ìƒíƒœ ê´€ë¦¬, ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ ì†Œì„¤ ì„ íƒë¶€í„°
ì±—ë´‡ì˜ ë‹µë³€ í‘œì‹œê¹Œì§€ ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ì„ ì œì–´í•˜ê³  ì¡°ìœ¨í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
"""
import streamlit as st
from dotenv import load_dotenv
from pathlib import Path
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import OpenAIEmbeddings

from utils.db_utils import get_all_literatures, get_literature_details_by_titles
from utils.load_and_split_text_utils import split_documents
from utils.vector_store_utils import get_or_create_vector_store
from utils.rag_chain_utils import create_conversational_rag_chain
from utils.graph_utils import create_graph
from utils.highlight_utils import highlight_text

def main():
    load_dotenv()
    st.set_page_config(page_title="RAG Chatbot", page_icon="ğŸ¤–", layout="wide")
    st.title("RAG ì±—ë´‡")

    CWD = Path.cwd()
    
    try:
        all_literatures = get_all_literatures()
        book_titles = [lit['title'] for lit in all_literatures]
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        st.info("`scripts/setup_database.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ DBë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return

    st.subheader("ê²€ìƒ‰í•  ì†Œì„¤ì„ ì„ íƒí•˜ì„¸ìš” (ë™ì¼ ì–¸ì–´ë§Œ ê°€ëŠ¥):")
    
    selected_book_titles = st.multiselect("ì†Œì„¤ ì„ íƒ", book_titles, label_visibility="collapsed")

    if st.button("ì„ íƒ ì™„ë£Œ ë° ë²¡í„° ì €ì¥ì†Œ ì¤€ë¹„"):
        if not selected_book_titles:
            st.warning("ì†Œì„¤ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•˜ì„¸ìš”!")
            st.session_state.clear()
        else:
            st.session_state.selected_book_titles = selected_book_titles
            st.rerun()

    st.divider()

    if 'selected_book_titles' in st.session_state and st.session_state.selected_book_titles:
        
        # --- 1. Data Preparation ---
        details = get_literature_details_by_titles(st.session_state.selected_book_titles)
        
        languages = {detail['language'] for detail in details}
        if len(languages) > 1:
            st.error("ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ëŠ” ì—¬ëŸ¬ ì–¸ì–´ì˜ ì±…ì„ ë™ì‹œì— ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë™ì¼í•œ ì–¸ì–´ì˜ ì±…ë§Œ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.stop()
        
        language = languages.pop()
        selected_names_display = ", ".join(st.session_state.selected_book_titles)

        with st.spinner("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë³¸ë¬¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            documents = [Document(page_content=d['body']) for d in details]
        
        with st.spinner("ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ëŠ” ì¤‘..."):
            all_chunks = split_documents(documents)

        embedding_model_name = "text-embedding-3-small"
        if language == 'ko':
            st.info(f"í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {embedding_model_name}")
            embeddings = OpenAIEmbeddings(model=embedding_model_name)
        else:
            st.info(f"ì˜ì–´(ê¸°ë³¸) ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {embedding_model_name}")
            embeddings = OpenAIEmbeddings(model=embedding_model_name)

        sanitized_model_name = embedding_model_name.replace("-", "_").replace("/", "_")
        sanitized_titles = [t.lower().replace(" ", "_") for t in sorted(st.session_state.selected_book_titles)]
        index_name_suffix = f"{language}_{sanitized_model_name}_{'_'.join(sanitized_titles)}"
        FAISS_INDEX_PATH = CWD / "faiss_literature" / index_name_suffix

        with st.spinner("ë²¡í„° ì €ì¥ì†Œë¥¼ ì¤€ë¹„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            vector_store = get_or_create_vector_store(all_chunks, FAISS_INDEX_PATH, embeddings)
            st.success("ë²¡í„° ì €ì¥ì†Œ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        # --- 2. UI Layout and RAG Chain ---
        main_col, source_col = st.columns([2, 1])

        with main_col:
            st.header(f"'{selected_names_display}' (ì–¸ì–´: {language.upper()})ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”")

            if 'rag_app' not in st.session_state:
                st.session_state.rag_app = create_graph(vector_store)

            if "messages" not in st.session_state:
                st.session_state.messages = []

            # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
            if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    status_placeholder = st.empty()
                    answer_placeholder = st.empty()
                    
                    inputs = {"question": prompt}
                    final_state = {}
                    
                    for step in st.session_state.rag_app.stream(inputs):
                        node_name = list(step.keys())[0]
                        status_message = {
                            "translate_question": "ì§ˆë¬¸ ë²ˆì—­ ì¤‘...",
                            "route_question": "ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ì¤‘...",
                            "retrieve": "ì†Œì„¤ ë‚´ìš© ê²€ìƒ‰ ì¤‘...",
                            "grade_documents": "ê²€ìƒ‰ëœ ë¬¸ì„œ í‰ê°€ ì¤‘...",
                            "generate": "ë‹µë³€ ìƒì„± ì¤‘...",
                            "translate_generation": "ë‹µë³€ ë²ˆì—­ ì¤‘...",
                        }.get(node_name, "")
                        if status_message:
                            status_placeholder.info(status_message)
                        final_state.update(step)

                    status_placeholder.empty()
                    
                    answer = final_state.get("translate_generation", {}).get("generation", "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    st.session_state.latest_sources = final_state.get("generate", {}).get("documents", [])
                    st.session_state.latest_keywords = final_state.get("generate", {}).get("keywords", [])
                    
                    answer_placeholder.markdown(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})
                    # Re-run to update the source column immediately
                    st.rerun()

        with source_col:
            st.subheader("ì°¸ê³  ìë£Œ")
            
            if st.session_state.get("latest_keywords"):
                st.markdown("**ì£¼ìš” í‚¤ì›Œë“œ:**")
                tags_html = "".join(f'<span style="background-color: #e0e0e0; border-radius: 5px; padding: 3px 8px; margin: 2px; display: inline-block;">{kw}</span>' for kw in st.session_state["latest_keywords"])
                st.markdown(tags_html, unsafe_allow_html=True)
                st.write("")

            if st.session_state.get("latest_sources"):
                keywords = st.session_state.get("latest_keywords", [])
                for i, doc in enumerate(st.session_state.latest_sources):
                    is_expanded = (i == 0)
                    with st.expander(f"ì¶œì²˜ {i+1} {'(ê°€ì¥ ê´€ë ¨ ë†’ìŒ)' if i == 0 else ''}", expanded=is_expanded):
                        highlighted_content = highlight_text(doc.page_content, keywords)
                        st.markdown(highlighted_content, unsafe_allow_html=True)
            else:
                st.info("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ê´€ë ¨ ì¶œì²˜ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
    else:
        st.info("ìœ„ì—ì„œ ê²€ìƒ‰í•  ì†Œì„¤ì„ ì„ íƒí•˜ê³  'ì„ íƒ ì™„ë£Œ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

if __name__ == '__main__':
    main()
